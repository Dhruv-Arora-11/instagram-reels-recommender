{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d953f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429243f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../interaction_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9afded",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    \"user_id\", \"click\", \"mod_price\", \"root_id\",\n",
    "    \"category_id\", \"exposed_time\" , \"p_hour\", \"p_date\" , \"author_id\" , \"parent_id\",\"title\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbb3c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in columns_to_drop:\n",
    "    df = df.drop(columns=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7719cfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>category_level</th>\n",
       "      <th>author_fans_count</th>\n",
       "      <th>watch_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>cvm_like</th>\n",
       "      <th>comment</th>\n",
       "      <th>follow</th>\n",
       "      <th>collect</th>\n",
       "      <th>forward</th>\n",
       "      <th>hate</th>\n",
       "      <th>tag_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>fre_city</th>\n",
       "      <th>fre_community_type</th>\n",
       "      <th>fre_city_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97474</td>\n",
       "      <td>1</td>\n",
       "      <td>46761</td>\n",
       "      <td>136</td>\n",
       "      <td>91.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>正能量</td>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "      <td>邯郸</td>\n",
       "      <td>unknown</td>\n",
       "      <td>三线城市</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97474</td>\n",
       "      <td>1</td>\n",
       "      <td>46761</td>\n",
       "      <td>136</td>\n",
       "      <td>91.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>电视机</td>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "      <td>邯郸</td>\n",
       "      <td>unknown</td>\n",
       "      <td>三线城市</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97474</td>\n",
       "      <td>1</td>\n",
       "      <td>46761</td>\n",
       "      <td>136</td>\n",
       "      <td>91.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>内容过于真实</td>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "      <td>邯郸</td>\n",
       "      <td>unknown</td>\n",
       "      <td>三线城市</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97474</td>\n",
       "      <td>2</td>\n",
       "      <td>46761</td>\n",
       "      <td>136</td>\n",
       "      <td>91.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>正能量</td>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "      <td>邯郸</td>\n",
       "      <td>unknown</td>\n",
       "      <td>三线城市</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97474</td>\n",
       "      <td>2</td>\n",
       "      <td>46761</td>\n",
       "      <td>136</td>\n",
       "      <td>91.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>电视机</td>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "      <td>邯郸</td>\n",
       "      <td>unknown</td>\n",
       "      <td>三线城市</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pid  category_level  author_fans_count  watch_time  duration  cvm_like  \\\n",
       "0  97474               1              46761         136      91.9     False   \n",
       "1  97474               1              46761         136      91.9     False   \n",
       "2  97474               1              46761         136      91.9     False   \n",
       "3  97474               2              46761         136      91.9     False   \n",
       "4  97474               2              46761         136      91.9     False   \n",
       "\n",
       "   comment  follow  collect  forward   hate tag_name gender  age fre_city  \\\n",
       "0    False   False    False    False  False      正能量      M   42       邯郸   \n",
       "1    False   False    False    False  False      电视机      M   42       邯郸   \n",
       "2    False   False    False    False  False   内容过于真实      M   42       邯郸   \n",
       "3    False   False    False    False  False      正能量      M   42       邯郸   \n",
       "4    False   False    False    False  False      电视机      M   42       邯郸   \n",
       "\n",
       "  fre_community_type fre_city_level  \n",
       "0            unknown           三线城市  \n",
       "1            unknown           三线城市  \n",
       "2            unknown           三线城市  \n",
       "3            unknown           三线城市  \n",
       "4            unknown           三线城市  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6091f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')  # Adjust the path based on where internal_logics folder is located\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from internal_logics.freq_mapper import SimplifiedFrequencyMapper\n",
    "from internal_logics.label_encode import SimplifiedLabelEncoder\n",
    "from internal_logics.gender_transform import GenderTransformer\n",
    "from internal_logics.log_transform import LogTransformer\n",
    "from internal_logics.gender_transform import GenderTransformer as GenderTransformer\n",
    "from internal_logics.log_transform import LogTransformer as LogTransformer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
    "\n",
    "boolean_cols = [\"cvm_like\", \"comment\", \"follow\", \"collect\", \"forward\", \"hate\"]\n",
    "categorical_cols = [\"tag_name\", \"fre_community_type\", \"fre_city_level\", \"fre_city\"]\n",
    "skewed_numeric_cols = [\"watch_time\", \"duration\", \"author_fans_count\"]\n",
    "\n",
    "skewed_numeric_pipeline = Pipeline(steps=[\n",
    "    ('log', LogTransformer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"booleans\", SimplifiedLabelEncoder(), boolean_cols),\n",
    "        (\"categoricals\", Pipeline(steps=[\n",
    "            ('freq_map', SimplifiedFrequencyMapper()),\n",
    "            ('label_enc', SimplifiedLabelEncoder())\n",
    "        ]), categorical_cols),\n",
    "        (\"gender\", GenderTransformer(), [\"gender\"]),\n",
    "        (\"skewed_numeric\", skewed_numeric_pipeline, skewed_numeric_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "143d9496",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', PCA(n_components=0.95))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67e17ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_of_data = df.sample(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8a09ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_only_preprocessor = preprocessor.fit_transform(sample_of_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28125f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_only_preprocessor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58ecad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "335750bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_both_preProcessor_PCA = pca.fit_transform(sample_only_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d403639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"transformed_data_for_dbscan_testing.npy\", sample_both_preProcessor_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a163c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = np.load(\"transformed_data_for_dbscan_testing.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6cdf9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0365b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here hte transformed_data is the  numpy array , not the dataframe ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d65696df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 1797  410 2225]\n",
      "Number of clusters found without noise: 3443\n",
      "total number of clusters : 3444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.DataFrame(transformed_data)\n",
    "\n",
    "# Fit and predict with DBSCAN\n",
    "dbscan = DBSCAN(eps=5, min_samples=15)\n",
    "cluster_labels = dbscan.fit_predict(df)\n",
    "print(cluster_labels)\n",
    "with open(\"cluster_labels.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cluster_labels, f)\n",
    "\n",
    "# Add results to original DataFrame\n",
    "df[\"dbscan_cluster_label\"] = cluster_labels\n",
    "\n",
    "# Print the number of clusters (excluding -1 which is noise/outliers)\n",
    "n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "\n",
    "print(f\"Number of clusters found without noise: {n_clusters}\")\n",
    "print(f\"total number of clusters : {len(set(cluster_labels))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c758e",
   "metadata": {},
   "source": [
    "Now , after we have the clusters , we want to predict with new data points , for that , we will take new data of the user , then go the position of it in the same space , then we have to go for the closest cluster . But how to calculate which is hte closest cluster , because the DBSCAN has no predict method , we have to do that ourselves . By common sense , we have the calculate which is the closest cluster to user datapoint . which distance can be calculated by the center of cluster.\n",
    "So we have to calculate the centeroids of the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e469b546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centroids calculated and saved successfully.\n",
      "Found 3443 centroids.\n"
     ]
    }
   ],
   "source": [
    "# This code should run after you have trained your main DBSCAN model\n",
    "# (after the cell with 'dbscan = DBSCAN(eps=5, min_samples=15)')\n",
    "\n",
    "# 1. Filter out the noise points (label == -1) before calculating centroids\n",
    "core_data = df[df['dbscan_cluster_label'] != -1]\n",
    "\n",
    "# 2. Group by cluster label and calculate the mean of all features\n",
    "# This gives us our \"pseudo-centroids\"\n",
    "cluster_centroids = core_data.groupby('dbscan_cluster_label').mean()\n",
    "\n",
    "# 3. Save the centroids to a file for later use in prediction\n",
    "import pickle\n",
    "\n",
    "with open(\"cluster_centroids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cluster_centroids, f)\n",
    "\n",
    "print(\"Cluster centroids calculated and saved successfully.\")\n",
    "print(f\"Found {len(cluster_centroids)} centroids.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4749380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe with the pid ,and one df with labels\n",
    "pid = pd.DataFrame(df['pid'])\n",
    "dbscan_cluster_label = pd.DataFrame(cluster_labels)\n",
    "\n",
    "# 1. Combine the 'pid' and 'dbscan_cluster_label' side-by-side (axis=1)\n",
    "df_video_clusters = pd.concat([pid, dbscan_cluster_label], axis=1)\n",
    "\n",
    "# 2. Assign the correct column names (if they aren't already set)\n",
    "df_video_clusters.columns = ['pid', 'dbscan_cluster_label']\n",
    "\n",
    "# 3. Save to CSV\n",
    "df_video_clusters.to_csv(\"video_clusters.csv\", index=False)\n",
    "\n",
    "# 4. View the result\n",
    "print(\"File saved successfully!\")\n",
    "df_video_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb000f27",
   "metadata": {},
   "source": [
    "calculating how many data points are there with each cluster.\n",
    "there were total of 500k data points in the sample , \n",
    "and there are only 3444 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4e8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,3444):\n",
    "    cluster_points = df[df[\"dbscan_cluster_label\"] == i]\n",
    "    print(f\"The the datapoints that belong to cluster label{i} are\")\n",
    "    print(len(cluster_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b2207bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96c68758",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m silhouette_score\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m mask = \u001b[43mdf\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mdbscan_cluster_label\u001b[39m\u001b[33m\"\u001b[39m] != -\u001b[32m1\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.sum() > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(df[\u001b[33m'\u001b[39m\u001b[33mdbscan_cluster_label\u001b[39m\u001b[33m'\u001b[39m][mask])) > \u001b[32m1\u001b[39m:\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# 7. Evaluate the model on the non-noise data points\u001b[39;00m\n\u001b[32m      6\u001b[39m     sil_score = silhouette_score(df[mask], df[\u001b[33m'\u001b[39m\u001b[33mdbscan_cluster_label\u001b[39m\u001b[33m'\u001b[39m][mask])\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "mask = df[\"dbscan_cluster_label\"] != -1\n",
    "if mask.sum() > 1 and len(set(df['dbscan_cluster_label'][mask])) > 1:\n",
    "    # 7. Evaluate the model on the non-noise data points\n",
    "    sil_score = silhouette_score(df[mask], df['dbscan_cluster_label'][mask])\n",
    "    db_score = davies_bouldin_score(df[mask], df['dbscan_cluster_label'][mask])\n",
    "    ch_score = calinski_harabasz_score(df[mask], df['dbscan_cluster_label'][mask])\n",
    "\n",
    "    print(\"--- DBSCAN Evaluation ---\")\n",
    "    print(f\"Silhouette Score: {sil_score} (higher is better)\")\n",
    "    print(f\"Davies-Bouldin Index: {db_score} (lower is better)\")\n",
    "    print(f\"Calinski-Harabasz Score: {ch_score} (higher is better)\")\n",
    "    print(\"-------------------------\")\n",
    "else:\n",
    "    print(\"Not enough clusters or data points for a meaningful evaluation. Adjust hyperparameters.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e77eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
