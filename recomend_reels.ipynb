{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f074687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "from sklearn.cluster import DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "167d963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"interaction_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9dcb497",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    \"user_id\", \"click\", \"mod_price\", \"root_id\",\n",
    "    \"category_id\", \"exposed_time\" , \"p_hour\", \"p_date\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2df9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from internal_logics.freq_mapper import SimplifiedFrequencyMapper as SimplifiedFrequencyMapper\n",
    "from internal_logics.label_encode import SimplifiedLabelEncoder as SimplifiedLabelEncoder\n",
    "from internal_logics.gender_transform import GenderTransformer as GenderTransformer\n",
    "from internal_logics.log_transform import LogTransformer as LogTransformer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
    "\n",
    "boolean_cols = [\"cvm_like\", \"comment\", \"follow\", \"collect\", \"forward\", \"hate\"]\n",
    "categorical_cols = [\"tag_name\", \"fre_community_type\", \"fre_city_level\", \"fre_city\"]\n",
    "skewed_numeric_cols = [\"watch_time\", \"duration\", \"author_fans_count\"]\n",
    "\n",
    "skewed_numeric_pipeline = Pipeline(steps=[\n",
    "    ('log', LogTransformer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"booleans\", SimplifiedLabelEncoder(), boolean_cols),\n",
    "        (\"categoricals\", Pipeline(steps=[\n",
    "            ('freq_map', SimplifiedFrequencyMapper()),\n",
    "            ('label_enc', SimplifiedLabelEncoder())\n",
    "        ]), categorical_cols),\n",
    "        (\"gender\", GenderTransformer(), [\"gender\"]),\n",
    "        (\"skewed_numeric\", skewed_numeric_pipeline, skewed_numeric_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b2b93ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', PCA(n_components=0.95))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7cd6855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After loading the file, we can confirm PCA chose 2 components.\n"
     ]
    }
   ],
   "source": [
    "with open(\"fitted_preprocessor_5.pkl\", \"rb\") as f:\n",
    "    loaded_pipeline = pickle.load(f)\n",
    "\n",
    "# 2. Access the PCA step and its attribute from the loaded object\n",
    "num_components_from_file = loaded_pipeline['pca'].n_components_\n",
    "\n",
    "print(f\"After loading the file, we can confirm PCA chose {num_components_from_file} components.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a5e674",
   "metadata": {},
   "source": [
    "What did PCA select???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f651f34",
   "metadata": {},
   "source": [
    "Applyign DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbf92c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# applying pca , preprocessing on training data and making transformed_data \n",
    "\n",
    "df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "dbscan_sample_raw = df_cleaned.sample(n=200000, random_state=42)\n",
    "\n",
    "with open(\"fitted_preprocessor_5.pkl\", \"rb\") as f:\n",
    "    full_pipeline = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d45d84e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saving\n",
    "# np.save(\"transformed_data_for_dbscan.npy\", transformed_data)\n",
    "\n",
    "transformed_data = np.load(\"transformed_data_for_dbscan.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccd20799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9efef11",
   "metadata": {},
   "source": [
    "If model already trained , then just import that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70eac11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dbscan_model.pkl\", \"rb\") as f:\n",
    "    loaded_dbscan_model = pickle.load(f)\n",
    "    \n",
    "cluster_labels = loaded_dbscan_model.labels_\n",
    "\n",
    "dbscan_sample_raw['dbscan_cluster_label'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4dfe1cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 21)\n"
     ]
    }
   ],
   "source": [
    "print(dbscan_sample_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94cc58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter out the noise points (label == -1) before calculating centroids\n",
    "core_data = dbscan_sample_raw[dbscan_sample_raw['dbscan_cluster_label'] != -1]\n",
    "cluster_centroids = core_data.drop(columns=['dbscan_cluster_label']).groupby(core_data['dbscan_cluster_label']).mean(numeric_only=True)\n",
    "\n",
    "with open(\"cluster_centroids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cluster_centroids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbeabc4",
   "metadata": {},
   "source": [
    "Predicting New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a249fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'transformed_data' is the output from your full_pipeline (from the .npy file)\n",
    "# Assume 'cluster_labels' are the labels from your fitted dbscan model\n",
    "\n",
    "# 1. Create a DataFrame from the PCA-transformed data\n",
    "transformed_df = pd.DataFrame(transformed_data)\n",
    "\n",
    "# 2. Add the cluster labels to this new DataFrame\n",
    "transformed_df['dbscan_cluster_label'] = cluster_labels\n",
    "\n",
    "# 3. Filter out noise points\n",
    "core_data_transformed = transformed_df[transformed_df['dbscan_cluster_label'] != -1]\n",
    "\n",
    "# 4. Calculate centroids on the TRANSFORMED data\n",
    "cluster_centroids_transformed = core_data_transformed.groupby('dbscan_cluster_label').mean()\n",
    "\n",
    "# 5. Save the CORRECT centroids\n",
    "with open(\"cluster_centroids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cluster_centroids_transformed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41d14648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor and cluster centroids loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "with open('cluster_centroids.pkl', 'rb') as f:\n",
    "    cluster_centroids = pickle.load(f)\n",
    "print(\"Preprocessor and cluster centroids loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f47dc0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    \"cvm_like\": [True], \"comment\": [False], \"follow\": [True],\n",
    "    \"collect\": [False], \"forward\": [False], \"hate\": [False],\n",
    "    \"tag_name\": [\"some_tag\"], \"fre_community_type\": [\"type_A\"],\n",
    "    \"fre_city_level\": [\"level_1\"], \"fre_city\": [\"city_X\"],\n",
    "    \"duration\": [1000.0], \"gender\": ['M'], \"author_fans_count\": [10000000],\n",
    "    \"watch_time\": [0.0], \"parent_id\":[30], \"age\":[20], \"category_level\":[2]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e9a2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from internal_logics.fallback import predict_with_fallback\n",
    "final_cluster = predict_with_fallback(new_data, full_pipeline , cluster_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fecbbfb",
   "metadata": {},
   "source": [
    "Prediction Videos Logic "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc37f47",
   "metadata": {},
   "source": [
    "Creating Video_clusters.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d47ecc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from internal_logics.video_clusters import video_clusters as vc\n",
    "# df_video_clusters = vc.makingVideoClusters(dbscan_sample_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09d6dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_clusters = pd.read_csv(\"video_clusters.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8a5df",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9745af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from internal_logics.get_recomendations import get_recommendations\n",
    "\n",
    "recommended_videos = get_recommendations(\n",
    "    target_video_pid=9999999,\n",
    "    target_cluster_label=final_cluster,\n",
    "    all_videos_df=dbscan_sample_raw,\n",
    "    video_cluster_map=df_video_clusters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38431539",
   "metadata": {},
   "source": [
    "Getting Actual Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0843dec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendation #1:\n",
      "  Title: 不要离开我\n",
      "  PID: 146585\n",
      "  Direct Link: https://fi.ee.tsinghua.edu.cn/datasets/short-video-dataset/raw_file/146585.mp4\n",
      "\n",
      "Recommendation #2:\n",
      "  Title: 弟弟回外婆家\n",
      "  PID: 67901\n",
      "  Direct Link: https://fi.ee.tsinghua.edu.cn/datasets/short-video-dataset/raw_file/67901.mp4\n",
      "\n",
      "Recommendation #3:\n",
      "  Title: 《究竟为什么》\n",
      "  PID: 81311\n",
      "  Direct Link: https://fi.ee.tsinghua.edu.cn/datasets/short-video-dataset/raw_file/81311.mp4\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from internal_logics.url_for_recomend import url_for_videos\n",
    "data = {\n",
    "    'pid': recommended_videos['pid'],\n",
    "    'title': recommended_videos['title'],\n",
    "    'author_id': recommended_videos['author_id'],\n",
    "    'watch_time': recommended_videos['watch_time']\n",
    "}\n",
    "recommended_videos = pd.DataFrame(data)\n",
    "\n",
    "# Let's remove duplicates for a cleaner list\n",
    "recommended_videos = recommended_videos.drop_duplicates(subset='pid').reset_index(drop=True)\n",
    "\n",
    "all_recomended_videos = url_for_videos(recommended_videos=recommended_videos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
